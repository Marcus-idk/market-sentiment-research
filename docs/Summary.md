# Summary â€” Complete Code Inventory

This file is autogenerated by `tools/generate_summary.py`. Do not edit by hand.

## Environment Variables (from `.env.example`)
- `OPENAI_API_KEY` - Required: OpenAI API key (for LLM analysis).
- `GEMINI_API_KEY` - Required: Google Gemini API key (for LLM analysis).
- `FINNHUB_API_KEY` - Required: Finnhub API key (market data fetching).
- `POLYGON_API_KEY` - Required: Polygon.io API key (news fetching).
- `REDDIT_CLIENT_ID` - Required: Reddit API credentials (PRAW OAuth).
- `REDDIT_CLIENT_SECRET` - Required: Reddit API credentials (PRAW OAuth).
- `REDDIT_USER_AGENT` - Required: Reddit API credentials (PRAW OAuth).
- `SYMBOLS` - Required: Stock symbols to track (comma-separated list). Example: SYMBOLS=AAPL,MSFT,TSLA,GOOGL
- `POLL_INTERVAL` - Required: Polling interval in seconds. Examples: 60=1 minute, 300=5 minutes, 600=10 minutes
- `DATABASE_PATH` - Optional: Database path. Default: data/database/trading_bot.db
- `STREAMLIT_PORT` - Optional: Streamlit UI port. Default: 8501 Used only when running `run_poller.py` with `-v`.
- `LOG_LEVEL` - Optional: Logging level name. Default: INFO Options: DEBUG, INFO, WARNING, ERROR, CRITICAL
- `LOG_FILE` - Optional: Log file path. Default: unset (console only). If set, logs also write to this file.
- `LOG_FORMAT` - Optional: Logging format string. Default: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

## Top-Level Files
- `README.md` - Landing page that points developers to detailed documentation in `docs/`.
- `requirements.txt` - Runtime and test dependencies (OpenAI, Gemini, httpx, pytest, etc.).
- `requirements-dev.txt` - Developer-only extras.
- `pytest.ini` - Pytest configuration (pythonpath, markers, default flags).
- `pyrightconfig.json` - Pyright type checker configuration.
- `.pre-commit-config.yaml` - Pre-commit hooks (format/lint/typecheck + generators).
- `.env.example` - Example environment configuration (copy to `.env` and set API keys).

## Docs Map
- `docs/Roadmap.md` - Project roadmap and next steps.
- `docs/Summary.md` - Autogenerated code inventory (`tools/generate_summary.py`).
- `docs/Test_Catalog.md` - Autogenerated pytest inventory (`tools/generate_test_catalog.py`).
- `docs/Test_Guide.md` - How to run and write tests.
- `docs/Writing_Code.md` - Coding rules and conventions.
- `docs/LLM_Providers_Guide.md` - LLM provider parameters and gotchas.
- `docs/Data_API_Reference.md` - Data layer reference notes.

## Code Inventory

### `analysis/__init__.py`
- Purpose: Analysis and classification modules for the trading bot.

### `analysis/news_importance.py`
- Purpose: Assign importance flags to news entries (stub implementation).
- Functions:
  - `label_importance` - Set ``is_important=True`` on every news entry and return the list.

### `analysis/urgency_detector.py`
- Purpose: Urgency detection helpers for news and social entries.
- Functions:
  - `detect_news_urgency` - Detect urgent news items. Stub: returns empty.
  - `detect_social_urgency` - Detect urgent social discussions. Stub: returns empty.
  - `_build_news_inputs` - Normalize news entries into urgency-scoring inputs.
  - `_build_social_inputs` - Normalize social discussions into urgency-scoring inputs.
  - `_log_stub_stats` - Log basic stats for stub urgency detection.
- Classes:
  - `UrgencyInput` - Normalized text + metadata for urgency scoring.

### `config/__init__.py`
- Purpose: Configuration package exposing settings modules for TradingBot.

### `config/llm/__init__.py`
- Purpose: Configuration settings for LLM providers.

### `config/llm/gemini.py`
- Purpose: Gemini LLM provider configuration settings.
- Classes:
  - `GeminiSettings` - Configuration for Gemini LLM access.
    - Methods:
      - `from_env` - Load Gemini settings from environment variables.

### `config/llm/openai.py`
- Purpose: OpenAI LLM provider configuration settings.
- Classes:
  - `OpenAISettings` - Configuration for OpenAI LLM access.
    - Methods:
      - `from_env` - Load OpenAI settings from environment variables.

### `config/providers/finnhub.py`
- Purpose: Finnhub provider configuration settings.
- Classes:
  - `FinnhubSettings` - Configuration settings for Finnhub API integration.
    - Methods:
      - `from_env` - Load Finnhub settings from environment variables.

### `config/providers/polygon.py`
- Purpose: Polygon.io provider configuration settings.
- Classes:
  - `PolygonSettings` - Configuration for Polygon.io API access.
    - Methods:
      - `from_env` - Load Polygon settings from environment variables.

### `config/providers/reddit.py`
- Purpose: Reddit provider configuration settings.
- Classes:
  - `RedditSettings` - Configuration for Reddit OAuth and polling behavior.
    - Methods:
      - `from_env` - Load Reddit settings from environment variables.

### `config/retry.py`
- Purpose: Centralized retry configuration for LLM and data providers.
- Classes:
  - `LLMRetryConfig` - Retry configuration for LLM providers (OpenAI, Gemini, etc.)
  - `DataRetryConfig` - Retry configuration for data providers (Finnhub, Polygon, etc.)

### `data/__init__.py`
- Purpose: Public data models, providers, and storage helpers for the trading bot.

### `data/base.py`
- Purpose: Core abstract base classes for data providers.
- Classes:
  - `DataSource` - Abstract base class for all data providers (Finnhub, Polygon, Reddit, etc.).
    - Methods:
      - `__init__` - Validate and store a human-readable provider name.
      - `validate_connection` - Test whether the remote service is reachable and credentials work.
  - `DataSourceError` - Base exception for data source related errors.
  - `NewsDataSource` - Abstract base class for data sources that provide news content.
    - Methods:
      - `fetch_incremental` - Fetch new news items using incremental cursors.
  - `SocialDataSource` - Abstract base class for data sources that provide social discussions.
    - Methods:
      - `fetch_incremental` - Fetch new social discussion items using incremental cursors.
  - `PriceDataSource` - Abstract base class for data sources that provide price/market data.
    - Methods:
      - `fetch_incremental` - Fetch the latest available price data.

### `data/models.py`
- Purpose: Domain models and validation helpers for news, prices, and analysis.
- Functions:
  - `_valid_http_url` - Check if url is a real host.
- Classes:
  - `Session` - Define trading session labels.
  - `Stance` - Define stance labels for model outputs.
  - `AnalysisType` - Define analysis type identifiers.
  - `Urgency` - Define urgency levels for notifications.
  - `NewsType` - Define news category labels.
  - `NewsItem` - Normalized news article content.
    - Methods:
      - `__post_init__` - Normalize fields and validate headline, source, URL, and news_type.
  - `NewsSymbol` - Symbol-level metadata associated with a news article.
    - Methods:
      - `__post_init__` - Normalize fields and validate symbol importance data.
  - `NewsEntry` - News item paired with its target symbol and importance flag.
    - Methods:
      - `__post_init__` - Validate symbol and importance flags for the news entry.
  - `SocialDiscussion` - Normalized social discussion thread (e.g., Reddit post with top comments).
    - Methods:
      - `__post_init__` - Validate and normalize social discussion fields.
  - `PriceData` - Single price observation for a symbol.
    - Methods:
      - `__post_init__` - Normalize fields and validate price, volume, and session.
  - `AnalysisResult` - Persisted model output for a symbol and analysis type.
    - Methods:
      - `__post_init__` - Normalize fields and validate analysis result payload.
  - `Holdings` - Portfolio holdings record with cost basis and notes.
    - Methods:
      - `__post_init__` - Normalize fields and validate holdings data.

### `data/providers/__init__.py`
- Purpose: Public provider facades for the trading bot.

### `data/providers/finnhub/__init__.py`
- Purpose: Finnhub provider package.

### `data/providers/finnhub/finnhub_client.py`
- Purpose: Finnhub API client wrapper.
- Classes:
  - `FinnhubClient` - Minimal async HTTP client wrapper for Finnhub API calls.
    - Methods:
      - `__init__` - Store Finnhub API settings.
      - `get` - Perform an authenticated GET request to the Finnhub API.
      - `validate_connection` - Validate API connection using a simple quote request.

### `data/providers/finnhub/finnhub_macro_news.py`
- Purpose: Macro news provider implementation.
- Classes:
  - `FinnhubMacroNewsProvider` - Fetches macro/market news from Finnhub's /news endpoint.
    - Methods:
      - `__init__` - Initialize the Finnhub macro news provider.
      - `validate_connection` - Return True when the Finnhub API is reachable.
      - `fetch_incremental` - Stream macro news incrementally using minId pagination.
      - `_parse_article` - Parse Finnhub macro news article into one or more NewsEntry objects.
      - `_extract_symbols_from_related` - Parse Finnhub related string into watchlisted symbols.

### `data/providers/finnhub/finnhub_news.py`
- Purpose: Company news provider implementation.
- Classes:
  - `FinnhubNewsProvider` - Fetches company news from Finnhub's /company-news endpoint.
    - Methods:
      - `__init__` - Initialize the Finnhub company news provider.
      - `validate_connection` - Return True when the Finnhub API is reachable.
      - `fetch_incremental` - Fetch company news for tracked symbols using overlap cursors.
      - `_resolve_symbol_cursor` - Pick the most specific cursor for a symbol (per-symbol over global).
      - `_parse_article` - Parse Finnhub company news article into a NewsEntry.

### `data/providers/finnhub/finnhub_prices.py`
- Purpose: Price provider implementation.
- Classes:
  - `FinnhubPriceProvider` - Fetches real-time quotes from Finnhub's /quote endpoint.
    - Methods:
      - `__init__` - Initialize the Finnhub price provider.
      - `validate_connection` - Return True when the Finnhub API is reachable.
      - `fetch_incremental` - Fetch latest quotes for configured symbols.
      - `_parse_quote` - Convert Finnhub /quote payload into PriceData.

### `data/providers/polygon/__init__.py`
- Purpose: Polygon.io data provider implementations.

### `data/providers/polygon/polygon_client.py`
- Purpose: Polygon.io API client wrapper.
- Functions:
  - `_extract_cursor_from_next_url` - Extract cursor parameter value from a Polygon next_url pagination link.
- Classes:
  - `PolygonClient` - Minimal async HTTP client wrapper for Polygon.io API calls.
    - Methods:
      - `__init__` - Store Polygon API settings.
      - `get` - Perform an authenticated GET request to the Polygon API.
      - `validate_connection` - Validate API connection using market status endpoint.

### `data/providers/polygon/polygon_macro_news.py`
- Purpose: Polygon.io macro news provider implementation.
- Classes:
  - `PolygonMacroNewsProvider` - Fetches macro/market news from Polygon.io's /v2/reference/news endpoint.
    - Methods:
      - `__init__` - Initialize the Polygon macro news provider.
      - `validate_connection` - Return True when the Polygon API is reachable.
      - `fetch_incremental` - Fetch macro news stream incrementally with overlap handling.
      - `_extract_cursor` - Extract cursor parameter from a Polygon next_url pagination link.
      - `_parse_article` - Parse Polygon news article into multiple NewsItems (one per matching symbol).
      - `_extract_symbols_from_tickers` - Extract symbols from tickers array, filtering to watchlist. Fall back to ['MARKET'].

### `data/providers/polygon/polygon_news.py`
- Purpose: Polygon.io company news provider implementation.
- Classes:
  - `PolygonNewsProvider` - Fetches company news from Polygon.io's /v2/reference/news endpoint.
    - Methods:
      - `__init__` - Initialize the Polygon company news provider.
      - `validate_connection` - Return True when the Polygon API is reachable.
      - `fetch_incremental` - Fetch company news per symbol with overlap handling and pagination.
      - `_resolve_symbol_cursor` - Return per-symbol cursor when available, else fall back to global.
      - `_fetch_symbol_news` - Fetch all news for a symbol, following pagination until complete.
      - `_extract_cursor` - Extract cursor parameter from a Polygon next_url pagination link.
      - `_parse_article` - Parse Polygon news article into a NewsEntry.

### `data/providers/reddit/__init__.py`
- Purpose: Reddit data provider implementations.

### `data/providers/reddit/reddit_client.py`
- Purpose: Reddit API client wrapper using PRAW.
- Classes:
  - `RedditClient` - Minimal Reddit API client wrapper using PRAW.
    - Methods:
      - `__init__` - Create a read-only PRAW client.
      - `validate_connection` - Validate OAuth credentials by calling /api/v1/me.

### `data/providers/reddit/reddit_social.py`
- Purpose: Reddit social sentiment provider.
- Classes:
  - `RedditSocialProvider` - Fetches Reddit posts and top comments for tracked symbols.
    - Methods:
      - `__init__` - Initialize the Reddit social provider.
      - `validate_connection` - Return True when Reddit API credentials are valid.
      - `fetch_incremental` - Fetch Reddit discussions for tracked symbols using incremental cursors.
      - `_resolve_symbol_cursor` - Return per-symbol cursor when available, else fall back to global.
      - `_fetch_symbol` - Search Reddit for posts mentioning the symbol and parse into discussions.
      - `_parse_submission` - Parse a Reddit submission into a SocialDiscussion, returning None if invalid.
      - `_build_content` - Concatenate post selftext and top comments; tolerant of comment fetch failures.

### `data/storage/__init__.py`
- Purpose: Public facade for trading bot data storage helpers.

### `data/storage/db_context.py`
- Purpose: Internal database context manager utilities for SQLite work.
- Functions:
  - `_cursor_context` - Context manager for SQLite cursors with auto-commit/rollback.

### `data/storage/state_enums.py`
- Purpose: Type-safe enums for provider watermark scopes and streams.
- Classes:
  - `Provider` - Supported news/data providers tracked by watermark state.
  - `Stream` - Logical stream identifiers within a provider.
  - `Scope` - Watermark scope (global vs per-symbol).

### `data/storage/storage_batch.py`
- Purpose: Batch operations for trading bot data.
- Functions:
  - `get_news_before` - Return news entries created at or before the cutoff.
  - `get_prices_before` - Return price rows created at or before the cutoff.
  - `commit_llm_batch` - Delete processed news/price rows up to cutoff in one transaction.

### `data/storage/storage_core.py`
- Purpose: Database lifecycle and connection management for trading bot data.
- Functions:
  - `connect` - Open a SQLite connection with required PRAGMAs enabled.
  - `_check_json1_support` - Check if SQLite JSON1 extension is available.
  - `init_database` - Initialize SQLite database, enforcing JSON1 support and schema.
  - `finalize_database` - Finalize database by checkpointing WAL and switching to DELETE mode.

### `data/storage/storage_crud.py`
- Purpose: CRUD operations for trading bot data storage.
- Functions:
  - `store_news_items` - Store news entries and symbol links.
  - `store_social_discussions` - Store social discussion threads.
  - `store_price_data` - Store price data with type conversions.
  - `get_news_since` - Retrieve news entries since the given timestamp.
  - `get_news_symbols` - Retrieve stored news symbol links, optionally filtered by symbol.
  - `get_social_discussions_since` - Retrieve social discussions since the given timestamp.
  - `get_price_data_since` - Retrieve price data since the given timestamp.
  - `get_all_holdings` - Retrieve all current holdings.
  - `get_analysis_results` - Retrieve analysis results, optionally filtered by symbol.
  - `upsert_analysis_result` - Insert or update analysis result with ON CONFLICT.
  - `upsert_holdings` - Insert or update holdings using ON CONFLICT.

### `data/storage/storage_utils.py`
- Purpose: Utility helpers and type conversions for trading bot storage.
- Functions:
  - `_normalize_url` - Normalize URL by stripping common tracking parameters.
  - `_datetime_to_iso` - Convert datetime to UTC ISO string format expected by database.
  - `_iso_to_datetime` - Convert ISO string from database to UTC datetime object.
  - `_decimal_to_text` - Convert Decimal to TEXT format for exact precision storage.
  - `_row_to_news_item` - Convert database row to NewsItem model.
  - `_row_to_news_symbol` - Convert database row to NewsSymbol model.
  - `_row_to_news_entry` - Convert joined row to NewsEntry domain model.
  - `_row_to_price_data` - Convert database row to PriceData model.
  - `_row_to_analysis_result` - Convert database row to AnalysisResult model.
  - `_row_to_holdings` - Convert database row to Holdings model.
  - `_row_to_social_discussion` - Convert database row to SocialDiscussion model.

### `data/storage/storage_watermark.py`
- Purpose: Typed CRUD helpers for the `last_seen_state` table.
- Functions:
  - `_normalize_symbol` - Normalize symbol requirements based on scope.
  - `_fetch_state_row` - Fetch raw watermark row matching provider/stream/scope/symbol.
  - `_upsert_state` - Insert or update watermark row for provider/stream/scope/symbol.
  - `get_last_seen_timestamp` - Read the timestamp watermark for the specified provider/stream/scope.
  - `set_last_seen_timestamp` - Persist a timestamp watermark for the provider/stream/scope tuple.
  - `get_last_seen_id` - Read the ID watermark for the specified provider/stream/scope.
  - `set_last_seen_id` - Persist an ID watermark for the provider/stream/scope tuple.

### `llm/__init__.py`
- Purpose: LLM providers facade for TradingBot.

### `llm/base.py`
- Purpose: Base interfaces and errors for LLM providers.
- Classes:
  - `LLMProvider` - Abstract base class for LLM providers.
    - Methods:
      - `__init__` - Initialize provider with arbitrary config passed to SDK calls.
      - `generate` - Generate text completion from prompt.
      - `validate_connection` - Test if the LLM provider is reachable and credentials work.
  - `LLMError` - Non-retryable LLM provider error (auth failures, invalid requests, etc.)

### `llm/providers/gemini.py`
- Purpose: Gemini LLM provider implementation.
- Classes:
  - `GeminiProvider` - Generate text with the Gemini API.
    - Methods:
      - `__init__` - Configure Gemini defaults; clamps minimum thinking budget.
      - `generate` - Generate a text response from Gemini; tool_choice requires function_declarations.
      - `_classify_gemini_exception` - Map Gemini SDK exceptions to RetryableError or LLMError.
      - `validate_connection` - Return True when Gemini API responds to models.list; False on failure.

### `llm/providers/openai.py`
- Purpose: OpenAI LLM provider implementation.
- Classes:
  - `OpenAIProvider` - Generate text with the OpenAI API.
    - Methods:
      - `__init__` - Configure OpenAI defaults; reasoning=low by default (avoid minimal+code_interpreter).
      - `generate` - Generate a text response from OpenAI (with retry mapping).
      - `_classify_openai_exception` - Map OpenAI SDK exceptions to RetryableError or LLMError.
      - `validate_connection` - Return True when OpenAI models.list succeeds; False when API errors.

### `run_poller.py`
- Purpose: Main entry point for the trading bot data poller.
- Functions:
  - `setup_environment` - Load environment and setup logging.
  - `build_config` - Parse environment variables and build configuration object.
  - `initialize_database` - Initialize database and return success status.
  - `launch_ui_process` - Launch Streamlit UI when enabled (``-v``), returning the child process.
  - `create_and_validate_providers` - Create and validate news and price providers.
  - `cleanup_ui_process` - Terminate Streamlit UI process (graceful then forced).
  - `main` - Main entry point for the poller.
- Classes:
  - `PollerConfig` - Configuration for the data poller.

### `tools/generate_summary.py`
- Purpose: Generate `docs/Summary.md` from code docstrings and `.env.example`.
- Functions:
  - `clean_docstring` - Return the first non-empty, trimmed line of a docstring, or None.
  - `is_property_method` - Return True when a function is a property or cached property.
  - `parse_methods` - Collect direct class methods, skipping properties.
  - `parse_module` - Parse a Python file and return its module, function, and class metadata.
  - `iter_source_files` - Return sorted source files to include in the summary.
  - `parse_env_example` - Extract env var descriptions from `.env.example` comments above each key.
  - `build_lines` - Render the summary as markdown lines.
  - `write_output` - Write the rendered summary to the output file.
  - `main` - Entry point to regenerate the Summary inventory.
- Classes:
  - `FunctionInfo` - A top-level function or class method entry.
  - `ClassInfo` - A module-level class and its direct methods.
  - `ModuleInfo` - Inventory data for one Python module.

### `tools/generate_test_catalog.py`
- Purpose: Generate `docs/Test_Catalog.md` from pytest collection and AST metadata.
- Functions:
  - `clean_docstring` - Return the first non-empty, trimmed line of a docstring, or None.
  - `marker_tags` - Derive high-level tags (async, network, shared, integration) from markers and path.
  - `parse_ast_metadata` - Parse module docstring, fixtures, and helper names from a test module AST.
  - `_is_fixture` - Return True when the given decorators include a pytest.fixture.
  - `collect_tests` - Collect tests via pytest and build initial FileReport objects keyed by path.
  - `ensure_reports_have_metadata` - Ensure every test file has a FileReport with AST-derived docs, fixtures, and helpers.
  - `format_tags` - Format a tag set as a space-separated string of [tag] entries.
  - `build_lines` - Build the markdown lines that make up the test catalog.
  - `write_output` - Write the rendered catalog lines to the output markdown file.
  - `main` - Entry point used by pre-commit to regenerate the test catalog.
- Classes:
  - `TestCase` - Metadata for a single collected test case.
  - `FixtureInfo` - Metadata for a pytest fixture defined in a test module.
  - `FileReport` - Aggregated test, fixture, and helper information for one test file.
    - Methods:
      - `add_test` - Add a test case to this report and update its tags.

### `ui/app_min.py`
- Purpose: Minimal Streamlit UI for browsing the TradingBot database.
- Functions:
  - `_friendly_table_name` - Return a human-friendly label for a table name.
  - `fetch_table_names` - Return sorted SQLite table names for the given database path.
  - `build_display_map` - Build a display-label-to-table-name mapping for the sidebar.

### `utils/__init__.py`
- Purpose: Utilities package (kept intentionally thin).

### `utils/datetime_utils.py`
- Purpose: Datetime helpers for UTC normalization and conversion.
- Functions:
  - `normalize_to_utc` - Return a timezone-aware UTC datetime.
  - `parse_rfc3339` - Parse RFC3339/ISO 8601 timestamp string to a UTC datetime.

### `utils/http.py`
- Purpose: Async HTTP helpers with retry and JSON parsing.
- Functions:
  - `get_json_with_retry` - Async HTTP GET with retries and JSON parsing.

### `utils/logging.py`
- Purpose: Centralized logging configuration for the trading bot.
- Functions:
  - `setup_logging` - Configure root logger from environment variables.

### `utils/market_sessions.py`
- Purpose: Market sessions utilities for US equity markets.
- Functions:
  - `_get_nyse_calendar` - Return cached NYSE calendar instance.
  - `classify_us_session` - Classify US equity market session from a UTC-aware timestamp.

### `utils/retry.py`
- Purpose: Retry utilities with exponential backoff and Retry-After support.
- Functions:
  - `parse_retry_after` - Parse Retry-After header value (numeric seconds or HTTP-date).
  - `retry_and_call` - Exponential backoff with jitter for retryable operations.
- Classes:
  - `RetryableError` - Signal that an operation should be retried.
    - Methods:
      - `__init__` - Create a retryable error with an optional retry-after delay.

### `utils/signals.py`
- Purpose: Signal handling utilities for graceful shutdown.
- Functions:
  - `register_graceful_shutdown` - Register SIGINT/SIGTERM handlers and return unregister callback.

### `utils/symbols.py`
- Purpose: Helpers for parsing and filtering symbol lists.
- Functions:
  - `_is_valid_symbol` - Return True if symbol matches supported exchange ticker formats.
  - `parse_symbols` - Parse a comma-separated string into a deduplicated list of uppercase symbols.

### `workflows/__init__.py`
- Purpose: Workflow orchestration for trading bot operations.

### `workflows/poller.py`
- Purpose: Data poller for continuous market data collection.
- Classes:
  - `DataBatch` - Data fetched from all providers in one cycle.
  - `PollStats` - Statistics from one polling cycle.
  - `DataPoller` - Poll configured providers for news and price data at regular intervals.
    - Methods:
      - `__init__` - Initialize the data poller.
      - `_plan_kwargs` - Build keyword args for provider.fetch_incremental based on available cursors.
      - `_fetch_all_data` - Fetch data from all providers concurrently.
      - `_process_prices` - Store only primary-provider prices; log mismatches >= $0.01.
      - `_log_urgent_items` - Log up to 10 urgent news items (then a remainder count).
      - `_log_urgent_social` - Log up to 10 urgent social items (then a remainder count).
      - `_process_news` - Store news, detect urgency, and update per-provider watermarks.
      - `_process_social` - Store social discussions and update watermarks.
      - `poll_once` - Execute one polling cycle.
      - `run` - Run the continuous polling loop.
      - `stop` - Request graceful shutdown of the polling loop.

### `workflows/watermarks.py`
- Purpose: Watermark planning and persistence helpers for news providers.
- Functions:
  - `_utc_now` - Return the current UTC datetime.
  - `_cfg_days` - Read first-run day window from settings, falling back to default.
  - `_clamp_future` - Clamp a timestamp to at most 60 seconds in the future.
  - `_is_global_bootstrap_symbol` - Return True when a GLOBAL-scope provider should bootstrap this symbol.
  - `is_macro_stream` - Return True when the provider handles macro news streams.
- Classes:
  - `CursorRule` - Describes how a provider/stream tracks watermarks.
  - `CursorPlan` - Hold cursor inputs for incremental fetches.
  - `WatermarkEngine` - Build fetch plans and persist provider watermarks.
    - Methods:
      - `build_plan` - Build cursor plan using first-run lookbacks and stored watermarks.
      - `commit_updates` - Persist updated watermarks; ID streams use ``last_fetched_max_id``.
      - `_get_settings` - Retrieve provider settings object or raise if missing.
